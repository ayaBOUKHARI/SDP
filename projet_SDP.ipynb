{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet SDP - Explications pour la Somme Ponderee\n",
    "\n",
    "## Contexte\n",
    "\n",
    "Dans le concours de l'internat de medecine, les candidats sont classes selon une somme ponderee de leurs notes. L'objectif est de fournir une **explication comprehensible** de pourquoi un candidat x est mieux classe qu'un candidat y.\n",
    "\n",
    "Au lieu de simplement montrer la formule de somme ponderee, on souhaite decomposer l'explication en **trade-offs** plus simples.\n",
    "\n",
    "### Definitions generales\n",
    "\n",
    "- **contribution[i]** = weight[i] × (x[i] - y[i])\n",
    "- **pros(x,y)** = criteres ou x est meilleur que y (contribution > 0)\n",
    "- **cons(x,y)** = criteres ou y est meilleur que x (contribution < 0)\n",
    "- **neutral(x,y)** = criteres ou x et y sont egaux (contribution = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données du problème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tableau des candidats:\n",
      "       A     B     C     D     E     F     G   Score\n",
      "a1  89.0  74.0  81.0  68.0  84.0  79.0  77.0  3566.0\n",
      "a2  71.0  84.0  91.0  79.0  78.0  73.5  77.0  3564.5\n",
      "x   85.0  81.0  71.0  69.0  75.0  81.0  88.0  3541.0\n",
      "y   81.0  81.0  75.0  63.0  67.0  88.0  95.0  3530.0\n",
      "z   74.0  89.0  74.0  81.0  68.0  84.0  79.0  3521.0\n",
      "t   74.0  71.0  84.0  91.0  77.0  76.0  73.0  3503.0\n",
      "u   72.0  75.0  66.0  85.0  88.0  66.0  93.0  3489.0\n",
      "v   71.0  73.0  63.0  92.0  76.0  79.0  93.0  3481.0\n",
      "w   79.0  69.0  78.0  76.0  67.0  84.0  79.0  3413.0\n",
      "w'  57.0  76.0  81.0  76.0  82.0  86.0  77.0  3395.0\n",
      "\n",
      "Poids: {'A': 8, 'B': 7, 'C': 7, 'D': 6, 'E': 6, 'F': 5, 'G': 6}\n"
     ]
    }
   ],
   "source": [
    "# Donnees du probleme\n",
    "criteria_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "full_names = ['Anatomie', 'Biologie', 'Chirurgie', 'Diagnostic', \n",
    "              'Epidemiologie', 'Forensic Pathology', 'Genetique']\n",
    "weights = np.array([8, 7, 7, 6, 6, 5, 6])\n",
    "\n",
    "# Tous les candidats\n",
    "candidates = {\n",
    "    'x': np.array([85, 81, 71, 69, 75, 81, 88]),\n",
    "    'y': np.array([81, 81, 75, 63, 67, 88, 95]),\n",
    "    'z': np.array([74, 89, 74, 81, 68, 84, 79]),\n",
    "    't': np.array([74, 71, 84, 91, 77, 76, 73]),\n",
    "    'u': np.array([72, 75, 66, 85, 88, 66, 93]),\n",
    "    'v': np.array([71, 73, 63, 92, 76, 79, 93]),\n",
    "    'w': np.array([79, 69, 78, 76, 67, 84, 79]),\n",
    "    \"w'\": np.array([57, 76, 81, 76, 82, 86, 77]),\n",
    "    'a1': np.array([89, 74, 81, 68, 84, 79, 77]),\n",
    "    'a2': np.array([71, 84, 91, 79, 78, 73.5, 77])\n",
    "}\n",
    "\n",
    "# Afficher le tableau des candidats\n",
    "print(\"Tableau des candidats:\")\n",
    "df_candidates = pd.DataFrame(candidates, index=criteria_names).T\n",
    "df_candidates['Score'] = [np.sum(weights * candidates[c]) for c in candidates]\n",
    "print(df_candidates.sort_values('Score', ascending=False))\n",
    "\n",
    "print(f\"\\nPoids: {dict(zip(criteria_names, weights))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions utiles\n",
    "Des fonctions utiles pour notre problème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_contributions(x_scores, y_scores, weights):\n",
    "    \"\"\"Calcule les contributions de chaque critere a la somme ponderee dans x > y\"\"\"\n",
    "    return weights * (x_scores - y_scores)\n",
    "\n",
    "def classify_criteria(contributions, epsilon=1e-6):\n",
    "    \"\"\"Classifie les criteres en pros, cons et neutral\"\"\"\n",
    "    pros = [i for i, c in enumerate(contributions) if c > epsilon]\n",
    "    cons = [i for i, c in enumerate(contributions) if c < -epsilon]\n",
    "    neutral = [i for i, c in enumerate(contributions) if abs(c) <= epsilon]\n",
    "    return pros, cons, neutral\n",
    "\n",
    "def display_comparison(cand1_name, cand2_name, candidates, weights, criteria_names):\n",
    "    \"\"\"Affiche les details d'une comparaison\"\"\"\n",
    "    c1 = candidates[cand1_name]\n",
    "    c2 = candidates[cand2_name]\n",
    "    \n",
    "    contributions = compute_contributions(c1, c2, weights)\n",
    "    pros, cons, neutral = classify_criteria(contributions)\n",
    "    \n",
    "    print(f\"Comparaison: {cand1_name} > {cand2_name}\")\n",
    "   \n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Critere': criteria_names,\n",
    "        'Poids': weights,\n",
    "        cand1_name: c1,\n",
    "        cand2_name: c2,\n",
    "        'Contribution': contributions\n",
    "    })\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    score1 = np.sum(weights * c1)\n",
    "    score2 = np.sum(weights * c2)\n",
    "    print(f\"\\nScore {cand1_name} = {score1}\")\n",
    "    print(f\"Score {cand2_name} = {score2}\")\n",
    "    print(f\"Difference = {score1 - score2}\")\n",
    "    \n",
    "    print(f\"\\npros({cand1_name},{cand2_name}) = {{{', '.join([criteria_names[i] for i in pros])}}}\")\n",
    "    print(f\"cons({cand1_name},{cand2_name}) = {{{', '.join([criteria_names[i] for i in cons])}}}\")\n",
    "    print(f\"neutral({cand1_name},{cand2_name}) = {{{', '.join([criteria_names[i] for i in neutral])}}}\")\n",
    "    \n",
    "    return contributions, pros, cons, neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Question 1 : Explication de type (1-1)\n",
    "\n",
    "## Definition\n",
    "\n",
    "- **Trade-off (1-1)** : paire (P, C) ou P ∈ pros, C ∈ cons, et contribution[P] + contribution[C] > 0\n",
    "- **Explication (1-1)** : ensemble de trade-offs (1-1) disjoints couvrant tous les elements de cons(x,y)\n",
    "\n",
    "## Formulation\n",
    "\n",
    "### Variables\n",
    "- z[p,c] ∈ {0,1} pour chaque paire valide (p ∈ pros, c ∈ cons)\n",
    "\n",
    "### Contraintes\n",
    "- C1: Chaque cons couvert exactement 1 fois: $\\sum_p z_{p,c} = 1$\n",
    "- C2: Chaque pro utilise au plus 1 fois: $\\sum_c z_{p,c} \\leq 1$\n",
    "- C3: Variables creees uniquement pour paires valides (contribution[p] + contribution[c] > 0)\n",
    "\n",
    "### Objectif\n",
    "Minimiser le nombre de trade-offs: $\\min \\sum_{p,c} z_{p,c}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_explanation_1_1(x_scores, y_scores, weights, criteria_names=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Question 1: Trouve une explication de type (1-1) pour x > y\n",
    "    Trade-off (1-1): une paire (P, C) ou P compense C\n",
    "    \"\"\"\n",
    "    n_criteria = len(x_scores)\n",
    "    if criteria_names is None:\n",
    "        criteria_names = [f\"C{i}\" for i in range(n_criteria)]\n",
    "    \n",
    "    contributions = compute_contributions(x_scores, y_scores, weights)\n",
    "    pros, cons, neutral = classify_criteria(contributions)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\npros = {[criteria_names[i] for i in pros]}\")\n",
    "        print(f\"cons = {[criteria_names[i] for i in cons]}\")\n",
    "    \n",
    "    # Verifications\n",
    "    if np.sum(contributions) <= 0:\n",
    "        print(\"Erreur: x n'est pas meilleur que y\")\n",
    "        return None, \"INVALID\"\n",
    "    \n",
    "    if len(cons) == 0:\n",
    "        if verbose:\n",
    "            print(\"Aucun cons. Pas besoin d'explication.\")\n",
    "        return [], \"TRIVIAL\"\n",
    "    \n",
    "    # Identifier les paires valides\n",
    "    epsilon = 0.01\n",
    "    valid_pairs = []\n",
    "    for p in pros:\n",
    "        for c in cons:\n",
    "            if contributions[p] + contributions[c] >= epsilon:\n",
    "                valid_pairs.append((p, c))\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nPaires valides (1-1):\")\n",
    "        for p, c in valid_pairs:\n",
    "            total = contributions[p] + contributions[c]\n",
    "            print(f\"  ({criteria_names[p]}, {criteria_names[c]}): {contributions[p]:+.1f} + ({contributions[c]:+.1f}) = {total:+.1f}\")\n",
    "    \n",
    "    # Verifier que chaque cons peut etre couvert\n",
    "    for c in cons:\n",
    "        if not any(p for p in pros if (p, c) in valid_pairs):\n",
    "            if verbose:\n",
    "                print(f\"\\n=== Aucune explication (1-1) n'existe ===\")\n",
    "                print(f\"Le cons {criteria_names[c]} ne peut etre couvert par aucun pro.\")\n",
    "            return None, \"INFEASIBLE\"\n",
    "    \n",
    "    # Modele Gurobi\n",
    "    model = gp.Model(\"explanation_1_1\")\n",
    "    model.Params.OutputFlag = 0\n",
    "    \n",
    "    z = {}\n",
    "    for p, c in valid_pairs:\n",
    "        z[p, c] = model.addVar(vtype=GRB.BINARY, name=f\"z_{criteria_names[p]}_{criteria_names[c]}\")\n",
    "    \n",
    "    model.update()\n",
    "    \n",
    "    # C1: Chaque cons couvert exactement 1 fois\n",
    "    for c in cons:\n",
    "        model.addConstr(\n",
    "            gp.quicksum(z[p, c] for p in pros if (p, c) in z) == 1,\n",
    "            name=f\"cover_{criteria_names[c]}\"\n",
    "        )\n",
    "    \n",
    "    # C2: Chaque pro utilise au plus 1 fois\n",
    "    for p in pros:\n",
    "        model.addConstr(\n",
    "            gp.quicksum(z[p, c] for c in cons if (p, c) in z) <= 1,\n",
    "            name=f\"use_{criteria_names[p]}\"\n",
    "        )\n",
    "    \n",
    "    # Objectif\n",
    "    model.setObjective(gp.quicksum(z[p, c] for p, c in valid_pairs), GRB.MINIMIZE)\n",
    "    \n",
    "    model.optimize()\n",
    "    \n",
    "    if model.status == GRB.OPTIMAL:\n",
    "        explanation = [(p, c) for p, c in valid_pairs if z[p, c].X > 0.5]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n=== Explication (1-1) trouvee ===\")\n",
    "            print(f\"Longueur: {len(explanation)}\")\n",
    "            print(\"\\nTrade-offs:\")\n",
    "            for p, c in explanation:\n",
    "                total = contributions[p] + contributions[c]\n",
    "                print(f\"  ({criteria_names[p]}, {criteria_names[c]}): {contributions[p]:+.1f} + ({contributions[c]:+.1f}) = {total:+.1f} > 0\")\n",
    "            \n",
    "            print(\"\\nConclusion:\")\n",
    "            for p, c in explanation:\n",
    "                print(f\"  L'avantage en {criteria_names[p]} compense le desavantage en {criteria_names[c]}\")\n",
    "        \n",
    "        return explanation, \"OPTIMAL\"\n",
    "    \n",
    "    elif model.status == GRB.INFEASIBLE:\n",
    "        if verbose:\n",
    "            print(\"\\n Aucune explication (1-1) n'existe\")\n",
    "        return None, \"INFEASIBLE\"\n",
    "    \n",
    "    return None, f\"STATUS_{model.status}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 1: x > y\n",
    "On teste la question 1 pour le couple x et y, on s'attend à avoir une explication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparaison: x > y\n",
      "Critere  Poids  x  y  Contribution\n",
      "      A      8 85 81            32\n",
      "      B      7 81 81             0\n",
      "      C      7 71 75           -28\n",
      "      D      6 69 63            36\n",
      "      E      6 75 67            48\n",
      "      F      5 81 88           -35\n",
      "      G      6 88 95           -42\n",
      "\n",
      "Score x = 3541\n",
      "Score y = 3530\n",
      "Difference = 11\n",
      "\n",
      "pros(x,y) = {A, D, E}\n",
      "cons(x,y) = {C, F, G}\n",
      "neutral(x,y) = {B}\n",
      "\n",
      "pros = ['A', 'D', 'E']\n",
      "cons = ['C', 'F', 'G']\n",
      "\n",
      "Paires valides (1-1):\n",
      "  (A, C): +32.0 + (-28.0) = +4.0\n",
      "  (D, C): +36.0 + (-28.0) = +8.0\n",
      "  (D, F): +36.0 + (-35.0) = +1.0\n",
      "  (E, C): +48.0 + (-28.0) = +20.0\n",
      "  (E, F): +48.0 + (-35.0) = +13.0\n",
      "  (E, G): +48.0 + (-42.0) = +6.0\n",
      "\n",
      "=== Explication (1-1) trouvee ===\n",
      "Longueur: 3\n",
      "\n",
      "Trade-offs:\n",
      "  (A, C): +32.0 + (-28.0) = +4.0 > 0\n",
      "  (D, F): +36.0 + (-35.0) = +1.0 > 0\n",
      "  (E, G): +48.0 + (-42.0) = +6.0 > 0\n",
      "\n",
      "Conclusion:\n",
      "  L'avantage en A compense le desavantage en C\n",
      "  L'avantage en D compense le desavantage en F\n",
      "  L'avantage en E compense le desavantage en G\n"
     ]
    }
   ],
   "source": [
    "display_comparison('x', 'y', candidates, weights, criteria_names)\n",
    "explanation, status = find_explanation_1_1(candidates['x'], candidates['y'], weights, criteria_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 1: w > w' \n",
    "Cette paire n'a pas d'explication possible "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparaison: w > w'\n",
      "Critere  Poids  w  w'  Contribution\n",
      "      A      8 79  57           176\n",
      "      B      7 69  76           -49\n",
      "      C      7 78  81           -21\n",
      "      D      6 76  76             0\n",
      "      E      6 67  82           -90\n",
      "      F      5 84  86           -10\n",
      "      G      6 79  77            12\n",
      "\n",
      "Score w = 3413\n",
      "Score w' = 3395\n",
      "Difference = 18\n",
      "\n",
      "pros(w,w') = {A, G}\n",
      "cons(w,w') = {B, C, E, F}\n",
      "neutral(w,w') = {D}\n",
      "\n",
      "pros = ['A', 'G']\n",
      "cons = ['B', 'C', 'E', 'F']\n",
      "\n",
      "Paires valides (1-1):\n",
      "  (A, B): +176.0 + (-49.0) = +127.0\n",
      "  (A, C): +176.0 + (-21.0) = +155.0\n",
      "  (A, E): +176.0 + (-90.0) = +86.0\n",
      "  (A, F): +176.0 + (-10.0) = +166.0\n",
      "  (G, F): +12.0 + (-10.0) = +2.0\n",
      "\n",
      "=== Aucune explication (1-1) n'existe ===\n",
      "Le cons B ne peut etre couvert par aucun pro.\n"
     ]
    }
   ],
   "source": [
    "display_comparison('w', \"w'\", candidates, weights, criteria_names)\n",
    "explanation, status = find_explanation_1_1(candidates['w'], candidates[\"w'\"], weights, criteria_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Question 2 : Explication de type (1-m)\n",
    "\n",
    "## Definition\n",
    "\n",
    "- **Trade-off (1-m)** : paire (P, {C1, ..., Cm}) ou un seul pro P compense plusieurs cons\n",
    "- Validite: contribution[P] + contribution[C1] + ... + contribution[Cm] > 0\n",
    "- **Explication (1-m)** : ensemble de trade-offs (1-m) disjoints couvrant tous les cons\n",
    "\n",
    "## Formulation\n",
    "\n",
    "### Variables\n",
    "- z[p,c] ∈ {0,1}: le cons c est assigne au pro p\n",
    "- y[p] ∈ {0,1}: le pro p est utilise\n",
    "\n",
    "### Contraintes\n",
    "- C1: Chaque cons couvert exactement 1 fois\n",
    "- C2: Lien z-y\n",
    "- C3: Validite du trade-off pour chaque pro utilise\n",
    "\n",
    "### Objectif\n",
    "Minimiser le nombre de trade-offs (= nombre de pros utilises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_explanation_1_m(x_scores, y_scores, weights, criteria_names=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Question 2: Trouve une explication de type (1-m) pour x > y\n",
    "    Trade-off (1-m): un pro compense plusieurs cons\n",
    "    \"\"\"\n",
    "    n_criteria = len(x_scores)\n",
    "    if criteria_names is None:\n",
    "        criteria_names = [f\"C{i}\" for i in range(n_criteria)]\n",
    "    \n",
    "    contributions = compute_contributions(x_scores, y_scores, weights)\n",
    "    pros, cons, neutral = classify_criteria(contributions)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\npros = {[criteria_names[i] for i in pros]}\")\n",
    "        print(f\"cons = {[criteria_names[i] for i in cons]}\")\n",
    "    \n",
    "    if np.sum(contributions) <= 0:\n",
    "        return None, \"INVALID\"\n",
    "    if len(cons) == 0:\n",
    "        return [], \"TRIVIAL\"\n",
    "    if len(pros) == 0:\n",
    "        return None, \"INFEASIBLE\"\n",
    "    \n",
    "    # Modele Gurobi\n",
    "    model = gp.Model(\"explanation_1_m\")\n",
    "    model.Params.OutputFlag = 0\n",
    "    \n",
    "    z = {}\n",
    "    for p in pros:\n",
    "        for c in cons:\n",
    "            z[p, c] = model.addVar(vtype=GRB.BINARY, name=f\"z_{criteria_names[p]}_{criteria_names[c]}\")\n",
    "    \n",
    "    y = {}\n",
    "    for p in pros:\n",
    "        y[p] = model.addVar(vtype=GRB.BINARY, name=f\"y_{criteria_names[p]}\")\n",
    "    \n",
    "    model.update()\n",
    "    \n",
    "    epsilon = 0.01\n",
    "    M = 10000\n",
    "    \n",
    "    # C1: Chaque cons couvert exactement 1 fois\n",
    "    for c in cons:\n",
    "        model.addConstr(gp.quicksum(z[p, c] for p in pros) == 1, name=f\"cover_{criteria_names[c]}\")\n",
    "    \n",
    "    # C2: Lien z-y\n",
    "    for p in pros:\n",
    "        for c in cons:\n",
    "            model.addConstr(z[p, c] <= y[p], name=f\"link_{criteria_names[p]}_{criteria_names[c]}\")\n",
    "    \n",
    "    # C3: Validite des trade-offs\n",
    "    for p in pros:\n",
    "        model.addConstr(\n",
    "            contributions[p] + gp.quicksum(z[p, c] * contributions[c] for c in cons) >= epsilon - M * (1 - y[p]),\n",
    "            name=f\"valid_{criteria_names[p]}\"\n",
    "        )\n",
    "    \n",
    "    # Objectif\n",
    "    model.setObjective(gp.quicksum(y[p] for p in pros), GRB.MINIMIZE)\n",
    "    \n",
    "    model.optimize()\n",
    "    \n",
    "    if model.status == GRB.OPTIMAL:\n",
    "        explanation = []\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nExplication (1-m) trouvee\")\n",
    "            print(f\"Longueur: {int(model.objVal)}\")\n",
    "            print(\"\\nTrade-offs:\")\n",
    "        \n",
    "        for p in pros:\n",
    "            if y[p].X > 0.5:\n",
    "                cons_for_p = [c for c in cons if z[p, c].X > 0.5]\n",
    "                explanation.append((p, cons_for_p))\n",
    "                \n",
    "                if verbose:\n",
    "                    cons_names = [criteria_names[c] for c in cons_for_p]\n",
    "                    contrib_p = contributions[p]\n",
    "                    contrib_cons = sum(contributions[c] for c in cons_for_p)\n",
    "                    total = contrib_p + contrib_cons\n",
    "                    print(f\"  (1-{len(cons_for_p)}) ({criteria_names[p]}, {{{', '.join(cons_names)}}}): \"\n",
    "                          f\"{contrib_p:+.1f} + ({contrib_cons:+.1f}) = {total:+.1f} > 0\")\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\n  Conclusion:\")\n",
    "            for p, cons_list in explanation:\n",
    "                cons_names = [criteria_names[c] for c in cons_list]\n",
    "                if len(cons_names) == 1:\n",
    "                    print(f\"  L'avantage en {criteria_names[p]} compense le desavantage en {cons_names[0]}\")\n",
    "                else:\n",
    "                    print(f\"  L'avantage en {criteria_names[p]} compense les desavantages en {', '.join(cons_names)}\")\n",
    "        \n",
    "        return explanation, \"OPTIMAL\"\n",
    "    \n",
    "    elif model.status == GRB.INFEASIBLE:\n",
    "        if verbose:\n",
    "            print(\"\\n Aucune explication (1-m) n'existe \")\n",
    "        return None, \"INFEASIBLE\"\n",
    "    \n",
    "    return None, f\"STATUS_{model.status}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2: w > w' \n",
    "Cette paire est explicable en 1-m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparaison: w > w'\n",
      "Critere  Poids  w  w'  Contribution\n",
      "      A      8 79  57           176\n",
      "      B      7 69  76           -49\n",
      "      C      7 78  81           -21\n",
      "      D      6 76  76             0\n",
      "      E      6 67  82           -90\n",
      "      F      5 84  86           -10\n",
      "      G      6 79  77            12\n",
      "\n",
      "Score w = 3413\n",
      "Score w' = 3395\n",
      "Difference = 18\n",
      "\n",
      "pros(w,w') = {A, G}\n",
      "cons(w,w') = {B, C, E, F}\n",
      "neutral(w,w') = {D}\n",
      "\n",
      "pros = ['A', 'G']\n",
      "cons = ['B', 'C', 'E', 'F']\n",
      "\n",
      "Explication (1-m) trouvee\n",
      "Longueur: 1\n",
      "\n",
      "Trade-offs:\n",
      "  (1-4) (A, {B, C, E, F}): +176.0 + (-170.0) = +6.0 > 0\n",
      "\n",
      "  Conclusion:\n",
      "  L'avantage en A compense les desavantages en B, C, E, F\n"
     ]
    }
   ],
   "source": [
    "display_comparison('w', \"w'\", candidates, weights, criteria_names)\n",
    "explanation, status = find_explanation_1_m(candidates['w'], candidates[\"w'\"], weights, criteria_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 2: u > v \n",
    "Cette paire doit échouer en l'explication 1-m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparaison: u > v\n",
      "Critere  Poids  u  v  Contribution\n",
      "      A      8 72 71             8\n",
      "      B      7 75 73            14\n",
      "      C      7 66 63            21\n",
      "      D      6 85 92           -42\n",
      "      E      6 88 76            72\n",
      "      F      5 66 79           -65\n",
      "      G      6 93 93             0\n",
      "\n",
      "Score u = 3489\n",
      "Score v = 3481\n",
      "Difference = 8\n",
      "\n",
      "pros(u,v) = {A, B, C, E}\n",
      "cons(u,v) = {D, F}\n",
      "neutral(u,v) = {G}\n",
      "\n",
      "pros = ['A', 'B', 'C', 'E']\n",
      "cons = ['D', 'F']\n",
      "\n",
      " Aucune explication (1-m) n'existe \n"
     ]
    }
   ],
   "source": [
    "display_comparison('u', 'v', candidates, weights, criteria_names)\n",
    "explanation, status = find_explanation_1_m(candidates['u'], candidates['v'], weights, criteria_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Question 3 : Explication de type (m-1)\n",
    "\n",
    "## Definition\n",
    "\n",
    "- **Trade-off (m-1)** : paire ({P1, ..., Pm}, C) ou plusieurs pros compensent un seul cons\n",
    "- Validite: contribution[P1] + ... + contribution[Pm] + contribution[C] > 0\n",
    "- **Explication (m-1)** : ensemble de trade-offs (m-1) disjoints couvrant tous les cons\n",
    "\n",
    "## Formulation\n",
    "\n",
    "### Variables\n",
    "- z[p,c] ∈ {0,1}: le pro p est assigne au cons c\n",
    "\n",
    "### Contraintes\n",
    "- C1: Chaque pro utilise au plus 1 fois\n",
    "- C2: Validite du trade-off pour chaque cons\n",
    "\n",
    "### Objectif\n",
    "Minimiser le nombre de pros utilises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_explanation_m_1(x_scores, y_scores, weights, criteria_names=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Question 3: Trouve une explication de type (m-1) pour x > y\n",
    "    Trade-off (m-1): plusieurs pros compensent un seul cons\n",
    "    \"\"\"\n",
    "    n_criteria = len(x_scores)\n",
    "    if criteria_names is None:\n",
    "        criteria_names = [f\"C{i}\" for i in range(n_criteria)]\n",
    "    \n",
    "    contributions = compute_contributions(x_scores, y_scores, weights)\n",
    "    pros, cons, neutral = classify_criteria(contributions)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\npros = {[criteria_names[i] for i in pros]}\")\n",
    "        print(f\"cons = {[criteria_names[i] for i in cons]}\")\n",
    "    \n",
    "    if np.sum(contributions) <= 0:\n",
    "        return None, \"INVALID\"\n",
    "    if len(cons) == 0:\n",
    "        return [], \"TRIVIAL\"\n",
    "    if len(pros) == 0:\n",
    "        return None, \"INFEASIBLE\"\n",
    "    \n",
    "    # Modele Gurobi\n",
    "    model = gp.Model(\"explanation_m_1\")\n",
    "    model.Params.OutputFlag = 0\n",
    "    \n",
    "    z = {}\n",
    "    for p in pros:\n",
    "        for c in cons:\n",
    "            z[p, c] = model.addVar(vtype=GRB.BINARY, name=f\"z_{criteria_names[p]}_{criteria_names[c]}\")\n",
    "    \n",
    "    model.update()\n",
    "    \n",
    "    epsilon = 0.01\n",
    "    \n",
    "    # C1: Chaque pro utilise au plus 1 fois\n",
    "    for p in pros:\n",
    "        model.addConstr(\n",
    "            gp.quicksum(z[p, c] for c in cons) <= 1,\n",
    "            name=f\"use_{criteria_names[p]}\"\n",
    "        )\n",
    "    \n",
    "    # C2: Validite des trade-offs pour chaque cons\n",
    "    for c in cons:\n",
    "        model.addConstr(\n",
    "            gp.quicksum(z[p, c] * contributions[p] for p in pros) + contributions[c] >= epsilon,\n",
    "            name=f\"valid_{criteria_names[c]}\"\n",
    "        )\n",
    "    \n",
    "    # Objectif\n",
    "    model.setObjective(gp.quicksum(z[p, c] for p in pros for c in cons), GRB.MINIMIZE)\n",
    "    \n",
    "    model.optimize()\n",
    "    \n",
    "    if model.status == GRB.OPTIMAL:\n",
    "        explanation = []\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nExplication (m-1) trouvee\")\n",
    "            print(\"\\nTrade-offs:\")\n",
    "        \n",
    "        for c in cons:\n",
    "            pros_for_c = [p for p in pros if z[p, c].X > 0.5]\n",
    "            explanation.append((pros_for_c, c))\n",
    "            \n",
    "            if verbose:\n",
    "                pros_names = [criteria_names[p] for p in pros_for_c]\n",
    "                contrib_pros = sum(contributions[p] for p in pros_for_c)\n",
    "                contrib_c = contributions[c]\n",
    "                total = contrib_pros + contrib_c\n",
    "                print(f\"  ({len(pros_for_c)}-1) ({{{', '.join(pros_names)}}}, {criteria_names[c]}): \"\n",
    "                      f\"{contrib_pros:+.1f} + ({contrib_c:+.1f}) = {total:+.1f} > 0\")\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nLongueur: {len(cons)} trade-offs\")\n",
    "            print(\"\\nConclusion:\")\n",
    "            for pros_list, c in explanation:\n",
    "                pros_names = [criteria_names[p] for p in pros_list]\n",
    "                if len(pros_names) == 1:\n",
    "                    print(f\"  L'avantage en {pros_names[0]} compense le desavantage en {criteria_names[c]}\")\n",
    "                else:\n",
    "                    print(f\"  Les avantages en {', '.join(pros_names)} compensent le desavantage en {criteria_names[c]}\")\n",
    "        \n",
    "        return explanation, \"OPTIMAL\"\n",
    "    \n",
    "    elif model.status == GRB.INFEASIBLE:\n",
    "        if verbose:\n",
    "            print(\"\\n Aucune explication (m-1) n'existe\")\n",
    "        return None, \"INFEASIBLE\"\n",
    "    \n",
    "    return None, f\"STATUS_{model.status}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 3: u > v \n",
    "On s'attend à ce qu'il y ait une explication de type m-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparaison: u > v\n",
      "Critere  Poids  u  v  Contribution\n",
      "      A      8 72 71             8\n",
      "      B      7 75 73            14\n",
      "      C      7 66 63            21\n",
      "      D      6 85 92           -42\n",
      "      E      6 88 76            72\n",
      "      F      5 66 79           -65\n",
      "      G      6 93 93             0\n",
      "\n",
      "Score u = 3489\n",
      "Score v = 3481\n",
      "Difference = 8\n",
      "\n",
      "pros(u,v) = {A, B, C, E}\n",
      "cons(u,v) = {D, F}\n",
      "neutral(u,v) = {G}\n",
      "\n",
      "pros = ['A', 'B', 'C', 'E']\n",
      "cons = ['D', 'F']\n",
      "\n",
      "Explication (m-1) trouvee\n",
      "\n",
      "Trade-offs:\n",
      "  (3-1) ({A, B, C}, D): +43.0 + (-42.0) = +1.0 > 0\n",
      "  (1-1) ({E}, F): +72.0 + (-65.0) = +7.0 > 0\n",
      "\n",
      "Longueur: 2 trade-offs\n",
      "\n",
      "Conclusion:\n",
      "  Les avantages en A, B, C compensent le desavantage en D\n",
      "  L'avantage en E compense le desavantage en F\n"
     ]
    }
   ],
   "source": [
    "display_comparison('u', 'v', candidates, weights, criteria_names)\n",
    "explanation, status = find_explanation_m_1(candidates['u'], candidates['v'], weights, criteria_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 3: y > z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparaison: y > z\n",
      "Critere  Poids  y  z  Contribution\n",
      "      A      8 81 74            56\n",
      "      B      7 81 89           -56\n",
      "      C      7 75 74             7\n",
      "      D      6 63 81          -108\n",
      "      E      6 67 68            -6\n",
      "      F      5 88 84            20\n",
      "      G      6 95 79            96\n",
      "\n",
      "Score y = 3530\n",
      "Score z = 3521\n",
      "Difference = 9\n",
      "\n",
      "pros(y,z) = {A, C, F, G}\n",
      "cons(y,z) = {B, D, E}\n",
      "neutral(y,z) = {}\n",
      "\n",
      "pros = ['A', 'C', 'F', 'G']\n",
      "cons = ['B', 'D', 'E']\n",
      "\n",
      " Aucune explication (m-1) n'existe\n"
     ]
    }
   ],
   "source": [
    "display_comparison('y', 'z', candidates, weights, criteria_names)\n",
    "explanation, status = find_explanation_m_1(candidates['y'], candidates['z'], weights, criteria_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 3: z > t \n",
    "Pour ce cas ni 1-m ni m-1 ne fonctionne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparaison: z > t\n",
      "Critere  Poids  z  t  Contribution\n",
      "      A      8 74 74             0\n",
      "      B      7 89 71           126\n",
      "      C      7 74 84           -70\n",
      "      D      6 81 91           -60\n",
      "      E      6 68 77           -54\n",
      "      F      5 84 76            40\n",
      "      G      6 79 73            36\n",
      "\n",
      "Score z = 3521\n",
      "Score t = 3503\n",
      "Difference = 18\n",
      "\n",
      "pros(z,t) = {B, F, G}\n",
      "cons(z,t) = {C, D, E}\n",
      "neutral(z,t) = {A}\n",
      "\n",
      "--- Test (1-m) ---\n",
      "\n",
      "pros = ['B', 'F', 'G']\n",
      "cons = ['C', 'D', 'E']\n",
      "\n",
      " Aucune explication (1-m) n'existe \n",
      "\n",
      "--- Test (m-1) ---\n",
      "\n",
      "pros = ['B', 'F', 'G']\n",
      "cons = ['C', 'D', 'E']\n",
      "\n",
      " Aucune explication (m-1) n'existe\n"
     ]
    }
   ],
   "source": [
    "display_comparison('z', 't', candidates, weights, criteria_names)\n",
    "print(\"\\n--- Test (1-m) ---\")\n",
    "exp_1m, status_1m = find_explanation_1_m(candidates['z'], candidates['t'], weights, criteria_names)\n",
    "print(\"\\n--- Test (m-1) ---\")\n",
    "exp_m1, status_m1 = find_explanation_m_1(candidates['z'], candidates['t'], weights, criteria_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Question 4 : Explication combinee (1-m) et (m-1)\n",
    "\n",
    "## Definition\n",
    "\n",
    "Une explication combinee peut utiliser:\n",
    "- Des trade-offs (1-m): un pro compense plusieurs cons\n",
    "- Des trade-offs (m-1): plusieurs pros compensent un cons\n",
    "\n",
    "## Strategie\n",
    "\n",
    "On determine le **mode** de chaque cons:\n",
    "- **'single'**: peut etre compense par 1 seul pro → eligible pour (1-m)\n",
    "- **'multi'**: necessite plusieurs pros → doit utiliser (m-1)\n",
    "\n",
    "## Formulation\n",
    "\n",
    "### Variables\n",
    "- z[p,c] ∈ {0,1}: le pro p contribue au cons c\n",
    "- y[p] ∈ {0,1}: le pro p est utilise\n",
    "\n",
    "### Contraintes\n",
    "- Pour cons 'single': exactement 1 pro, avec validite globale du pro\n",
    "- Pour cons 'multi': somme des contributions >= epsilon\n",
    "- Exclusivite entre modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_explanation_combined(x_scores, y_scores, weights, criteria_names=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Question 4: Trouve une explication combinant (1-m) et (m-1) pour x > y\n",
    "    \n",
    "    Le mode de chaque cons (1-m ou m-1) est une VARIABLE DE DECISION,\n",
    "    pas pre-determine. Le solveur choisit la meilleure configuration.\n",
    "    \"\"\"\n",
    "    n_criteria = len(x_scores)\n",
    "    if criteria_names is None:\n",
    "        criteria_names = [f\"C{i}\" for i in range(n_criteria)]\n",
    "\n",
    "    contributions = compute_contributions(x_scores, y_scores, weights)\n",
    "    pros, cons, neutral = classify_criteria(contributions)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\npros = {[criteria_names[i] for i in pros]}\")\n",
    "        print(f\"cons = {[criteria_names[i] for i in cons]}\")\n",
    "        print(f\"\\nContributions:\")\n",
    "        for i in pros:\n",
    "            print(f\"  {criteria_names[i]}: {contributions[i]:+.1f}\")\n",
    "        for i in cons:\n",
    "            print(f\"  {criteria_names[i]}: {contributions[i]:+.1f}\")\n",
    "\n",
    "    if np.sum(contributions) <= 0:\n",
    "        print(\"Erreur: x n'est pas meilleur que y\")\n",
    "        return None, \"INVALID\"\n",
    "    if len(cons) == 0:\n",
    "        return {}, \"TRIVIAL\"\n",
    "    if len(pros) == 0:\n",
    "        return None, \"INFEASIBLE\"\n",
    "\n",
    "    # Modele Gurobi\n",
    "    model = gp.Model(\"explanation_combined\")\n",
    "    model.Params.OutputFlag = 0\n",
    "\n",
    "    epsilon = 0.01\n",
    "    M = 10000\n",
    "\n",
    "    # === VARIABLES ===\n",
    "    \n",
    "    # z[p,c]: le pro p contribue au cons c\n",
    "    z = {}\n",
    "    for p in pros:\n",
    "        for c in cons:\n",
    "            z[p, c] = model.addVar(vtype=GRB.BINARY, name=f\"z_{criteria_names[p]}_{criteria_names[c]}\")\n",
    "\n",
    "    # mode_1m[c]: 1 si cons c est en mode (1-m) (couvert par 1 seul pro)\n",
    "    #             0 si cons c est en mode (m-1) (couvert par plusieurs pros)\n",
    "    mode_1m = {}\n",
    "    for c in cons:\n",
    "        mode_1m[c] = model.addVar(vtype=GRB.BINARY, name=f\"mode_{criteria_names[c]}\")\n",
    "\n",
    "    # y[p]: 1 si le pro p est utilise\n",
    "    y = {}\n",
    "    for p in pros:\n",
    "        y[p] = model.addVar(vtype=GRB.BINARY, name=f\"y_{criteria_names[p]}\")\n",
    "\n",
    "    model.update()\n",
    "\n",
    "    # === CONTRAINTES ===\n",
    "\n",
    "    # Lien y[p] avec z[p,c]\n",
    "    for p in pros:\n",
    "        for c in cons:\n",
    "            model.addConstr(z[p, c] <= y[p], name=f\"link_{criteria_names[p]}_{criteria_names[c]}\")\n",
    "\n",
    "    # Chaque cons doit etre couvert par au moins 1 pro\n",
    "    for c in cons:\n",
    "        model.addConstr(\n",
    "            gp.quicksum(z[p, c] for p in pros) >= 1,\n",
    "            name=f\"cover_{criteria_names[c]}\"\n",
    "        )\n",
    "\n",
    "    # Contrainte de mode: si mode_1m[c]=1, exactement 1 pro couvre c\n",
    "    # si mode_1m[c]=0, au moins 1 pro (possiblement plusieurs)\n",
    "    for c in cons:\n",
    "        n_pros_c = gp.quicksum(z[p, c] for p in pros)\n",
    "        # Si mode_1m = 1: n_pros_c = 1\n",
    "        # Si mode_1m = 0: n_pros_c >= 1 (deja garanti par cover)\n",
    "        model.addConstr(n_pros_c <= 1 + M * (1 - mode_1m[c]), name=f\"mode_upper_{criteria_names[c]}\")\n",
    "        model.addConstr(n_pros_c >= 1 * mode_1m[c], name=f\"mode_lower_{criteria_names[c]}\")\n",
    "\n",
    "    # Validite par cons (toujours): somme des contributions >= epsilon\n",
    "    for c in cons:\n",
    "        model.addConstr(\n",
    "            gp.quicksum(z[p, c] * contributions[p] for p in pros) + contributions[c] >= epsilon,\n",
    "            name=f\"valid_cons_{criteria_names[c]}\"\n",
    "        )\n",
    "\n",
    "    # Validite par pro (pour 1-m): si un pro couvre des cons en mode 1-m,\n",
    "    # sa contribution + contributions de tous ses cons 1-m >= epsilon\n",
    "    for p in pros:\n",
    "        # Somme des contributions des cons en mode 1-m couverts par p\n",
    "        # C'est: contrib[p] + sum_c (z[p,c] * mode_1m[c] * contrib[c])\n",
    "        # Mais z[p,c] * mode_1m[c] est non-lineaire\n",
    "        # On utilise une variable auxiliaire: w[p,c] = z[p,c] * mode_1m[c]\n",
    "        pass  # On va simplifier ci-dessous\n",
    "\n",
    "    # Simplification: on verifie la validite 1-m pour chaque pro\n",
    "    # Si un pro p couvre plusieurs cons en mode 1-m, la somme doit etre valide\n",
    "    # contrib[p] + sum_c(z[p,c] * contrib[c] pour c en mode 1-m) >= epsilon\n",
    "    \n",
    "    # Variable auxiliaire: w[p,c] = z[p,c] AND mode_1m[c]\n",
    "    w = {}\n",
    "    for p in pros:\n",
    "        for c in cons:\n",
    "            w[p, c] = model.addVar(vtype=GRB.BINARY, name=f\"w_{criteria_names[p]}_{criteria_names[c]}\")\n",
    "            # w[p,c] = 1 ssi z[p,c]=1 ET mode_1m[c]=1\n",
    "            model.addConstr(w[p, c] <= z[p, c])\n",
    "            model.addConstr(w[p, c] <= mode_1m[c])\n",
    "            model.addConstr(w[p, c] >= z[p, c] + mode_1m[c] - 1)\n",
    "\n",
    "    model.update()\n",
    "\n",
    "    # Validite 1-m pour chaque pro: si le pro est utilise en mode 1-m\n",
    "    for p in pros:\n",
    "        # has_1m[p] = 1 si p couvre au moins un cons en mode 1-m\n",
    "        has_1m = model.addVar(vtype=GRB.BINARY, name=f\"has1m_{criteria_names[p]}\")\n",
    "        sum_w = gp.quicksum(w[p, c] for c in cons)\n",
    "        model.addConstr(has_1m <= sum_w)\n",
    "        model.addConstr(has_1m * M >= sum_w)\n",
    "        \n",
    "        # Si has_1m = 1, alors contrib[p] + sum(w[p,c] * contrib[c]) >= epsilon\n",
    "        model.addConstr(\n",
    "            contributions[p] + gp.quicksum(w[p, c] * contributions[c] for c in cons) >= epsilon - M * (1 - has_1m),\n",
    "            name=f\"valid_pro_{criteria_names[p]}\"\n",
    "        )\n",
    "\n",
    "    # Exclusivite: un pro utilise en mode (m-1) ne peut pas couvrir d'autres cons\n",
    "    # Si z[p,c]=1 et mode_1m[c]=0, alors p ne couvre que c\n",
    "    for p in pros:\n",
    "        for c in cons:\n",
    "            # z[p,c]=1 et mode_1m[c]=0 implique sum_{c'!=c} z[p,c'] = 0\n",
    "            # Equivalent: sum_{c'} z[p,c'] <= 1 + M*(1-z[p,c]) + M*mode_1m[c]\n",
    "            model.addConstr(\n",
    "                gp.quicksum(z[p, c2] for c2 in cons) <= 1 + M * (1 - z[p, c]) + M * mode_1m[c],\n",
    "                name=f\"excl_{criteria_names[p]}_{criteria_names[c]}\"\n",
    "            )\n",
    "\n",
    "    # === OBJECTIF ===\n",
    "    model.setObjective(gp.quicksum(z[p, c] for p in pros for c in cons), GRB.MINIMIZE)\n",
    "\n",
    "    model.optimize()\n",
    "\n",
    "    if model.status == GRB.OPTIMAL:\n",
    "        if verbose:\n",
    "            print(f\"\\n=== Explication combinee trouvee ===\")\n",
    "            print(f\"Nombre de liens: {int(model.objVal)}\")\n",
    "        \n",
    "        # Construire l'explication\n",
    "        tradeoffs_1m = []  # (pro, [cons])\n",
    "        tradeoffs_m1 = []  # ([pros], cons)\n",
    "        \n",
    "        # Identifier les modes\n",
    "        cons_in_1m = [c for c in cons if mode_1m[c].X > 0.5]\n",
    "        cons_in_m1 = [c for c in cons if mode_1m[c].X < 0.5]\n",
    "        \n",
    "        # Trade-offs (1-m): regrouper les cons par pro\n",
    "        pro_to_cons = {}\n",
    "        for c in cons_in_1m:\n",
    "            for p in pros:\n",
    "                if z[p, c].X > 0.5:\n",
    "                    if p not in pro_to_cons:\n",
    "                        pro_to_cons[p] = []\n",
    "                    pro_to_cons[p].append(c)\n",
    "        \n",
    "        for p, cons_list in pro_to_cons.items():\n",
    "            tradeoffs_1m.append((p, cons_list))\n",
    "        \n",
    "        # Trade-offs (m-1): pour chaque cons en mode m-1\n",
    "        for c in cons_in_m1:\n",
    "            pros_for_c = [p for p in pros if z[p, c].X > 0.5]\n",
    "            tradeoffs_m1.append((pros_for_c, c))\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\nTrade-offs:\")\n",
    "            \n",
    "            for p, cons_list in tradeoffs_1m:\n",
    "                cons_names = [criteria_names[c] for c in cons_list]\n",
    "                contrib_p = contributions[p]\n",
    "                contrib_cons = sum(contributions[c] for c in cons_list)\n",
    "                total = contrib_p + contrib_cons\n",
    "                print(f\"  (1-{len(cons_list)}) ({criteria_names[p]}, {{{', '.join(cons_names)}}}): \"\n",
    "                      f\"{contrib_p:+.1f} + ({contrib_cons:+.1f}) = {total:+.1f} > 0\")\n",
    "            \n",
    "            for pros_list, c in tradeoffs_m1:\n",
    "                pros_names = [criteria_names[p] for p in pros_list]\n",
    "                contrib_pros = sum(contributions[p] for p in pros_list)\n",
    "                contrib_c = contributions[c]\n",
    "                total = contrib_pros + contrib_c\n",
    "                print(f\"  ({len(pros_list)}-1) ({{{', '.join(pros_names)}}}, {criteria_names[c]}): \"\n",
    "                      f\"{contrib_pros:+.1f} + ({contrib_c:+.1f}) = {total:+.1f} > 0\")\n",
    "\n",
    "            print(\"\\nConclusion:\")\n",
    "            for p, cons_list in tradeoffs_1m:\n",
    "                cons_names = [criteria_names[c] for c in cons_list]\n",
    "                if len(cons_names) == 1:\n",
    "                    print(f\"  L'avantage en {criteria_names[p]} compense le desavantage en {cons_names[0]}\")\n",
    "                else:\n",
    "                    print(f\"  L'avantage en {criteria_names[p]} compense les desavantages en {', '.join(cons_names)}\")\n",
    "            \n",
    "            for pros_list, c in tradeoffs_m1:\n",
    "                pros_names = [criteria_names[p] for p in pros_list]\n",
    "                if len(pros_names) == 1:\n",
    "                    print(f\"  L'avantage en {pros_names[0]} compense le desavantage en {criteria_names[c]}\")\n",
    "                else:\n",
    "                    print(f\"  Les avantages en {', '.join(pros_names)} compensent le desavantage en {criteria_names[c]}\")\n",
    "\n",
    "        return {'1m': tradeoffs_1m, 'm1': tradeoffs_m1}, \"OPTIMAL\"\n",
    "\n",
    "    elif model.status == GRB.INFEASIBLE:\n",
    "        if verbose:\n",
    "            print(\"\\n Aucune explication combinee n'existe \")\n",
    "        return None, \"INFEASIBLE\"\n",
    "\n",
    "    return None, f\"STATUS_{model.status}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 4: z > t (necessite combinaison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparaison: z > t\n",
      "Critere  Poids  z  t  Contribution\n",
      "      A      8 74 74             0\n",
      "      B      7 89 71           126\n",
      "      C      7 74 84           -70\n",
      "      D      6 81 91           -60\n",
      "      E      6 68 77           -54\n",
      "      F      5 84 76            40\n",
      "      G      6 79 73            36\n",
      "\n",
      "Score z = 3521\n",
      "Score t = 3503\n",
      "Difference = 18\n",
      "\n",
      "pros(z,t) = {B, F, G}\n",
      "cons(z,t) = {C, D, E}\n",
      "neutral(z,t) = {A}\n",
      "\n",
      "pros = ['B', 'F', 'G']\n",
      "cons = ['C', 'D', 'E']\n",
      "\n",
      "Contributions:\n",
      "  B: +126.0\n",
      "  F: +40.0\n",
      "  G: +36.0\n",
      "  C: -70.0\n",
      "  D: -60.0\n",
      "  E: -54.0\n",
      "\n",
      "=== Explication combinee trouvee ===\n",
      "Nombre de liens: 4\n",
      "\n",
      "Trade-offs:\n",
      "  (1-2) (B, {D, E}): +126.0 + (-114.0) = +12.0 > 0\n",
      "  (2-1) ({F, G}, C): +76.0 + (-70.0) = +6.0 > 0\n",
      "\n",
      "En langage naturel:\n",
      "  L'avantage en B compense les desavantages en D, E\n",
      "  Les avantages en F, G compensent le desavantage en C\n"
     ]
    }
   ],
   "source": [
    "display_comparison('z', 't', candidates, weights, criteria_names)\n",
    "explanation, status = find_explanation_combined(candidates['z'], candidates['t'], weights, criteria_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question 4: a1 > a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparaison: a1 > a2\n",
      "Critere  Poids  a1   a2  Contribution\n",
      "      A      8  89 71.0         144.0\n",
      "      B      7  74 84.0         -70.0\n",
      "      C      7  81 91.0         -70.0\n",
      "      D      6  68 79.0         -66.0\n",
      "      E      6  84 78.0          36.0\n",
      "      F      5  79 73.5          27.5\n",
      "      G      6  77 77.0           0.0\n",
      "\n",
      "Score a1 = 3566\n",
      "Score a2 = 3564.5\n",
      "Difference = 1.5\n",
      "\n",
      "pros(a1,a2) = {A, E, F}\n",
      "cons(a1,a2) = {B, C, D}\n",
      "neutral(a1,a2) = {G}\n",
      "\n",
      "pros = ['A', 'E', 'F']\n",
      "cons = ['B', 'C', 'D']\n",
      "\n",
      "Contributions:\n",
      "  A: +144.0\n",
      "  E: +36.0\n",
      "  F: +27.5\n",
      "  B: -70.0\n",
      "  C: -70.0\n",
      "  D: -66.0\n",
      "\n",
      " Aucune explication combinee n'existe \n"
     ]
    }
   ],
   "source": [
    "display_comparison('a1', 'a2', candidates, weights, criteria_names)\n",
    "explanation, status = find_explanation_combined(candidates['a1'], candidates['a2'], weights, criteria_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Resume: Toutes les comparaisons du classement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RESUME: Types d'explications pour chaque comparaison\n",
      "================================================================================\n",
      "Comparaison (1-1) (1-m) (m-1) Combinee\n",
      "      x > y    OK    OK    OK       OK\n",
      "      y > z     -     -     -        -\n",
      "      z > t     -     -     -       OK\n",
      "      t > u     -     -     -        -\n",
      "      u > v     -     -    OK       OK\n",
      "      v > w     -     -    OK       OK\n",
      "     w > w'     -    OK     -       OK\n"
     ]
    }
   ],
   "source": [
    "# Classement: x > y > z > t > u > v > w > w'\n",
    "ranking = ['x', 'y', 'z', 't', 'u', 'v', 'w', \"w'\"]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RESUME: Types d'explications pour chaque comparaison\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(len(ranking) - 1):\n",
    "    c1, c2 = ranking[i], ranking[i+1]\n",
    "    \n",
    "    # Test (1-1)\n",
    "    _, status_11 = find_explanation_1_1(candidates[c1], candidates[c2], weights, criteria_names, verbose=False)\n",
    "    # Test (1-m)\n",
    "    _, status_1m = find_explanation_1_m(candidates[c1], candidates[c2], weights, criteria_names, verbose=False)\n",
    "    # Test (m-1)\n",
    "    _, status_m1 = find_explanation_m_1(candidates[c1], candidates[c2], weights, criteria_names, verbose=False)\n",
    "    # Test combine\n",
    "    _, status_comb = find_explanation_combined(candidates[c1], candidates[c2], weights, criteria_names, verbose=False)\n",
    "    \n",
    "    results.append({\n",
    "        'Comparaison': f\"{c1} > {c2}\",\n",
    "        '(1-1)': 'OK' if status_11 == 'OPTIMAL' else '-',\n",
    "        '(1-m)': 'OK' if status_1m == 'OPTIMAL' else '-',\n",
    "        '(m-1)': 'OK' if status_m1 == 'OPTIMAL' else '-',\n",
    "        'Combinee': 'OK' if status_comb == 'OPTIMAL' else '-'\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fonction utilitaire: Expliquer une comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain(cand1_name, cand2_name):\n",
    "    \"\"\"\n",
    "    Fonction complete pour expliquer pourquoi cand1 > cand2\n",
    "    Essaie tous les types d'explications et retourne la plus simple\n",
    "    \"\"\"\n",
    "    c1 = candidates[cand1_name]\n",
    "    c2 = candidates[cand2_name]\n",
    "    \n",
    "    display_comparison(cand1_name, cand2_name, candidates, weights, criteria_names)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Recherche de la meilleure explication...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Essayer (1-1)\n",
    "    exp, status = find_explanation_1_1(c1, c2, weights, criteria_names, verbose=False)\n",
    "    if status == \"OPTIMAL\":\n",
    "        print(\"\\n>>> Explication (1-1) trouvee!\")\n",
    "        find_explanation_1_1(c1, c2, weights, criteria_names, verbose=True)\n",
    "        return\n",
    "    \n",
    "    # Essayer (1-m)\n",
    "    exp, status = find_explanation_1_m(c1, c2, weights, criteria_names, verbose=False)\n",
    "    if status == \"OPTIMAL\":\n",
    "        print(\"\\n>>> Explication (1-m) trouvee!\")\n",
    "        find_explanation_1_m(c1, c2, weights, criteria_names, verbose=True)\n",
    "        return\n",
    "    \n",
    "    # Essayer (m-1)\n",
    "    exp, status = find_explanation_m_1(c1, c2, weights, criteria_names, verbose=False)\n",
    "    if status == \"OPTIMAL\":\n",
    "        print(\"\\n>>> Explication (m-1) trouvee!\")\n",
    "        find_explanation_m_1(c1, c2, weights, criteria_names, verbose=True)\n",
    "        return\n",
    "    \n",
    "    # Essayer combinee\n",
    "    exp, status = find_explanation_combined(c1, c2, weights, criteria_names, verbose=False)\n",
    "    if status == \"OPTIMAL\":\n",
    "        print(\"\\n>>> Explication combinee trouvee!\")\n",
    "        find_explanation_combined(c1, c2, weights, criteria_names, verbose=True)\n",
    "        return\n",
    "    \n",
    "    print(\"\\n>>> Aucune explication trouvee!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparaison: z > t\n",
      "Critere  Poids  z  t  Contribution\n",
      "      A      8 74 74             0\n",
      "      B      7 89 71           126\n",
      "      C      7 74 84           -70\n",
      "      D      6 81 91           -60\n",
      "      E      6 68 77           -54\n",
      "      F      5 84 76            40\n",
      "      G      6 79 73            36\n",
      "\n",
      "Score z = 3521\n",
      "Score t = 3503\n",
      "Difference = 18\n",
      "\n",
      "pros(z,t) = {B, F, G}\n",
      "cons(z,t) = {C, D, E}\n",
      "neutral(z,t) = {A}\n",
      "\n",
      "============================================================\n",
      "Recherche de la meilleure explication...\n",
      "============================================================\n",
      "\n",
      ">>> Explication combinee trouvee!\n",
      "\n",
      "pros = ['B', 'F', 'G']\n",
      "cons = ['C', 'D', 'E']\n",
      "\n",
      "Contributions:\n",
      "  B: +126.0\n",
      "  F: +40.0\n",
      "  G: +36.0\n",
      "  C: -70.0\n",
      "  D: -60.0\n",
      "  E: -54.0\n",
      "\n",
      "=== Explication combinee trouvee ===\n",
      "Nombre de liens: 4\n",
      "\n",
      "Trade-offs:\n",
      "  (1-2) (B, {D, E}): +126.0 + (-114.0) = +12.0 > 0\n",
      "  (2-1) ({F, G}, C): +76.0 + (-70.0) = +6.0 > 0\n",
      "\n",
      "En langage naturel:\n",
      "  L'avantage en B compense les desavantages en D, E\n",
      "  Les avantages en F, G compensent le desavantage en C\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation\n",
    "explain('z', 't')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparaison: a1 > a2\n",
      "Critere  Poids  a1   a2  Contribution\n",
      "      A      8  89 71.0         144.0\n",
      "      B      7  74 84.0         -70.0\n",
      "      C      7  81 91.0         -70.0\n",
      "      D      6  68 79.0         -66.0\n",
      "      E      6  84 78.0          36.0\n",
      "      F      5  79 73.5          27.5\n",
      "      G      6  77 77.0           0.0\n",
      "\n",
      "Score a1 = 3566\n",
      "Score a2 = 3564.5\n",
      "Difference = 1.5\n",
      "\n",
      "pros(a1,a2) = {A, E, F}\n",
      "cons(a1,a2) = {B, C, D}\n",
      "neutral(a1,a2) = {G}\n",
      "\n",
      "============================================================\n",
      "Recherche de la meilleure explication...\n",
      "============================================================\n",
      "\n",
      ">>> Aucune explication trouvee!\n"
     ]
    }
   ],
   "source": [
    "explain('a1', 'a2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
